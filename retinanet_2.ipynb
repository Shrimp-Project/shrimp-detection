{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from datasets.datagen import load_data\n",
    "from models.retinanet import RetinaNet\n",
    "from models.fpn import FPN50, FPN101\n",
    "from models.focal_loss import FocalLoss\n",
    "\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = 'sgd'\n",
    "OPTIM_BASE_LR = 0.001\n",
    "OPTIM_MOMENTUM = 0.9\n",
    "OPTIM_ALPHA = 0.5\n",
    "OPTIM_EPS = 1e-8\n",
    "OPTIM_WEIGHT_DECAY = 1e-4\n",
    "OPTIM_BETA = (0.9, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(conv_body, num_classes):\n",
    "    networks_map = {\n",
    "        'ResNet50_FPN': FPN50,\n",
    "        'ResNet101_FPN': FPN101\n",
    "    }\n",
    "\n",
    "    model = RetinaNet(networks_map[conv_body], num_classes)\n",
    "    return model\n",
    "\n",
    "def config_optimizer(param):\n",
    "    print(f\"using {OPTIMIZER}: base_learning_rate = {OPTIM_BASE_LR}, momentum = {OPTIM_MOMENTUM}, weight_decay = {OPTIM_WEIGHT_DECAY}\")\n",
    "    if OPTIMIZER == 'sgd':\n",
    "        optimizer = optim.SGD(param, lr=OPTIM_BASE_LR, momentum=OPTIM_MOMENTUM, weight_decay=OPTIM_WEIGHT_DECAY)\n",
    "    elif OPTIMIZER == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(param, lr=OPTIM_BASE_LR, momentum=OPTIM_MOMENTUM, alpha=OPTIM_ALPHA, eps=OPTIM_EPS, weight_decay=OPTIM_WEIGHT_DECAY)\n",
    "    elif OPTIMIZER == 'adam':\n",
    "        optimizer = optim.Adam(param, lr=OPTIM_BASE_LR, betas=OPTIM_BETA, eps=OPTIM_EPS, weight_decay=OPTIM_WEIGHT_DECAY)\n",
    "    else:\n",
    "        AssertionError('optimizer can not be recognized.')\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONV_BODY = 'ResNet50_FPN'\n",
    "MODEL_NUM_CLASSES = 1\n",
    "MODEL_CHECKPOINT_DIR = 'D:/ForME/3_Data/shrimp/checkpoint'\n",
    "\n",
    "TRAIN_AUTO_RESUME = False\n",
    "TRAIN_RESUME_FILE = ''\n",
    "TRAIN_DATASET = ('D:/ForME/3_Data/shrimp/train', (600, 600), 1) # dir_path, image_size(800, ), batch_size(8)\n",
    "TRAIN_MAX_ITER = 100\n",
    "\n",
    "VALID_DATASET = ('D:/ForME/3_Data/shrimp/val', (600, 600), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint', loss=None):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = loss\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "    \n",
    "    def __call__(self, val_loss, model, epoch):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, epoch)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, epoch)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, epoch):\n",
    "        if self.verbose:\n",
    "            print(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\") \n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'loss': self.best_score,\n",
    "            'epoch': epoch\n",
    "        }\n",
    "        torch.save(state, os.path.join(self.path, f\"0_fpn50_b1_600_{epoch}_{val_loss:.3f}.pkl\"))\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_model():\n",
    "    start_iter = 0\n",
    "    min_loss = None\n",
    "    if os.path.exists(os.path.join(MODEL_CHECKPOINT_DIR, f\"FPN50.pkl\")):\n",
    "        if TRAIN_AUTO_RESUME:\n",
    "            checkpoints = torch.load(os.path.join(MODEL_CHECKPOINT_DIR, TRAIN_RESUME_FILE))\n",
    "            start_iter = checkpoints['epoch']\n",
    "            if start_iter > 0:\n",
    "                weights = checkpoints['net']\n",
    "                min_loss = checkpoints['loss']\n",
    "    else:\n",
    "        weights = None\n",
    "    model = create(MODEL_CONV_BODY, MODEL_NUM_CLASSES)\n",
    "    return model, weights, start_iter, min_loss\n",
    "\n",
    "def setup_train_model(model, weights, train=False):\n",
    "    if weights is not None:\n",
    "        model.load_state_dict(weights)\n",
    "    else:\n",
    "        # init_weight(model)\n",
    "        print('weight init')\n",
    "    if not torch.cuda.is_available():\n",
    "        raise print(f\"You could use GPU for train model\")\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    model, weight, start_iter, min_loss = create_train_model()\n",
    "    setup_train_model(model, weight, train=True)\n",
    "\n",
    "    trainloader = load_data(TRAIN_DATASET)\n",
    "    validloader = load_data(VALID_DATASET)\n",
    "    optimizer = config_optimizer(param=model.parameters())\n",
    "    criterion = FocalLoss(num_classes=MODEL_NUM_CLASSES)\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    avg_train_losses = []\n",
    "    avg_valid_losses = []\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True, path=MODEL_CHECKPOINT_DIR, loss=min_loss)\n",
    "\n",
    "    for cur_iter in range(start_iter, TRAIN_MAX_ITER):\n",
    "        print(f\"Epoch: {cur_iter}\")\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        model.freeze_bn()\n",
    "        for batch_idx, (inputs, loc_targets, cls_targets) in enumerate(trainloader):\n",
    "            inputs = torch.autograd.Variable(inputs.cuda())\n",
    "            loc_targets = torch.autograd.Variable(loc_targets.cuda())\n",
    "            cls_targets = torch.autograd.Variable(cls_targets.cuda())\n",
    "\n",
    "            # print(loc_targets.shape)\n",
    "            optimizer.zero_grad()\n",
    "            loc_preds, cls_preds = model(inputs)\n",
    "            # print(loc_preds.shape)\n",
    "            loc_loss, cls_loss = criterion(loc_preds, loc_targets, cls_preds, cls_targets)\n",
    "            loss = loc_loss + cls_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "            # show status\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"batch idx: {batch_idx} => loc_loss: {loc_loss.item()} || cls_loss: {cls_loss.item()}  || train_loss: {loss.item()}\")\n",
    "        \n",
    "        \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (inputs, loc_targets, cls_targets) in enumerate(validloader):\n",
    "            inputs = torch.autograd.Variable(inputs.cuda())\n",
    "            loc_target = torch.autograd.Variable(loc_target.cuda())\n",
    "            cls_target = torch.autograd.Variable(cls_target.cuda())\n",
    "\n",
    "            loc_preds, cls_preds = model(inputs)\n",
    "            loc_loss, cls_loss = criterion(loc_preds, loc_target, cls_preds, cls_target)\n",
    "            loss = loc_loss + cls_loss\n",
    "            valid_losses.append(loss.item())\n",
    "        \n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        print(f\"[epoch: {cur_iter} / {TRAIN_MAX_ITER} || train_loss: {train_loss:.5f} || valid_loss: {valid_loss:.5f}]\")\n",
    "\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "\n",
    "        early_stopping(valid_loss, model, cur_iter)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    return  model, avg_train_losses, avg_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight init\n",
      "using sgd: base_learning_rate = 0.001, momentum = 0.9, weight_decay = 0.0001\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\shrimp-project\\lib\\site-packages\\torch\\nn\\functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx: 0 => loc_loss: 1.0443321466445923 || cls_loss: 140.2132568359375  || train_loss: 141.25758361816406\n",
      "batch idx: 10 => loc_loss: 1.1017905473709106 || cls_loss: 0.9683222770690918  || train_loss: 2.070112705230713\n",
      "batch idx: 20 => loc_loss: 1.0324469804763794 || cls_loss: 4.159339427947998  || train_loss: 5.191786289215088\n",
      "batch idx: 30 => loc_loss: 1.0849738121032715 || cls_loss: 3.2628188133239746  || train_loss: 4.347792625427246\n",
      "batch idx: 40 => loc_loss: 1.112111210823059 || cls_loss: 2.0044779777526855  || train_loss: 3.116589069366455\n",
      "batch idx: 50 => loc_loss: 1.1228498220443726 || cls_loss: 1.53373384475708  || train_loss: 2.656583786010742\n",
      "batch idx: 60 => loc_loss: 1.0883634090423584 || cls_loss: 1.0899275541305542  || train_loss: 2.178290843963623\n",
      "batch idx: 70 => loc_loss: 1.0747389793395996 || cls_loss: 0.7310431003570557  || train_loss: 1.8057820796966553\n",
      "batch idx: 80 => loc_loss: 1.0168358087539673 || cls_loss: 0.7084653973579407  || train_loss: 1.7253012657165527\n",
      "batch idx: 90 => loc_loss: 1.1026703119277954 || cls_loss: 0.6885457038879395  || train_loss: 1.7912160158157349\n",
      "batch idx: 100 => loc_loss: 1.012974739074707 || cls_loss: 0.5997917652130127  || train_loss: 1.6127665042877197\n",
      "batch idx: 110 => loc_loss: 1.1090166568756104 || cls_loss: 0.637249231338501  || train_loss: 1.7462658882141113\n",
      "batch idx: 120 => loc_loss: 1.021667718887329 || cls_loss: 0.5809014439582825  || train_loss: 1.6025691032409668\n",
      "batch idx: 130 => loc_loss: 1.069625735282898 || cls_loss: 0.5579900741577148  || train_loss: 1.6276158094406128\n",
      "batch idx: 140 => loc_loss: 1.1027741432189941 || cls_loss: 0.5394385457038879  || train_loss: 1.6422126293182373\n",
      "batch idx: 150 => loc_loss: 1.0432031154632568 || cls_loss: 0.4531424641609192  || train_loss: 1.4963455200195312\n",
      "batch idx: 160 => loc_loss: 1.041943907737732 || cls_loss: 0.5974203944206238  || train_loss: 1.639364242553711\n",
      "batch idx: 170 => loc_loss: 1.0821555852890015 || cls_loss: 0.5920007824897766  || train_loss: 1.6741564273834229\n",
      "batch idx: 180 => loc_loss: 1.1199880838394165 || cls_loss: 0.6077627539634705  || train_loss: 1.7277507781982422\n",
      "batch idx: 190 => loc_loss: 1.070398211479187 || cls_loss: 0.6530655026435852  || train_loss: 1.723463773727417\n",
      "batch idx: 200 => loc_loss: 1.0433470010757446 || cls_loss: 0.675469696521759  || train_loss: 1.7188167572021484\n",
      "batch idx: 210 => loc_loss: 1.0851771831512451 || cls_loss: 0.4901861548423767  || train_loss: 1.5753633975982666\n",
      "batch idx: 220 => loc_loss: 1.0742039680480957 || cls_loss: 0.6660121083259583  || train_loss: 1.7402160167694092\n",
      "batch idx: 230 => loc_loss: 1.0240341424942017 || cls_loss: 0.4029170274734497  || train_loss: 1.4269511699676514\n",
      "batch idx: 240 => loc_loss: 1.0872455835342407 || cls_loss: 0.46380987763404846  || train_loss: 1.5510554313659668\n",
      "batch idx: 250 => loc_loss: 1.1242319345474243 || cls_loss: 0.8248501420021057  || train_loss: 1.9490821361541748\n",
      "batch idx: 260 => loc_loss: 1.1085611581802368 || cls_loss: 0.7246977686882019  || train_loss: 1.833258867263794\n",
      "batch idx: 270 => loc_loss: 1.007029414176941 || cls_loss: 0.5570279955863953  || train_loss: 1.5640573501586914\n",
      "batch idx: 280 => loc_loss: 1.090635061264038 || cls_loss: 0.44704514741897583  || train_loss: 1.5376801490783691\n",
      "batch idx: 290 => loc_loss: 1.116528868675232 || cls_loss: 0.6347845196723938  || train_loss: 1.7513134479522705\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'loc_target' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14504/480877549.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14504/2412424774.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_targets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mloc_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[0mcls_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'loc_target' referenced before assignment"
     ]
    }
   ],
   "source": [
    "model, train_loss, valid_loss = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e32529c96856fd5c77a9cb8e707c5e11ccf57f199250bc146689ddab2cf49e75"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('shrimp-project': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
